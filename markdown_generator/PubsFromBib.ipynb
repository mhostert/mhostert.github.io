{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pybtex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpybtex\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatabase\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput\u001b[39;00m \u001b[39mimport\u001b[39;00m bibtex\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpybtex\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatabase\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbibtex\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtime\u001b[39;00m \u001b[39mimport\u001b[39;00m strptime\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pybtex'"
     ]
    }
   ],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"journal\":{\n",
    "        \"file\": \"pubs.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    },\n",
    "#     \"proceeding\": {\n",
    "#         \"file\" : \"proceedings.bib\",\n",
    "#         \"venuekey\": \"booktitle\",\n",
    "#         \"venue-pretext\": \"In the proceedings of \",\n",
    "#         \"collection\" : {\"name\":\"publications\",\n",
    "#                         \"permalink\":\"/publication/\"}\n",
    "        \n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\"#.join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripchar_plain(s):\n",
    "    return s#.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\").replace(\"^\",\"-\").replace(\"--\",\"-\").replace('\"','')\n",
    "def stripchar_rich(s):\n",
    "    return s#.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\"^\",\"-\").replace(\"--\",\"-\").replace(\"$\",\"\").replace('\"','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "    bibdata.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCESSFULLY PARSED 2022arXiv220704137A: \" {DarkNews: a Python-based event generator for heavy neutral  ... \"\n",
      "SUCESSFULLY PARSED 2022arXiv220607100K: \" {Dipole-Coupled Neutrissimo Explanations of the MiniBooNE Ex ... \"\n",
      "SUCESSFULLY PARSED 2022arXiv220512273A: \" {A New Way To Seek Out Dark Neutrino Sectors And To Boldly E ... \"\n",
      "SUCESSFULLY PARSED 2022arXiv220102603H: \" {Dark sectors in neutron-shining-through-a-wall and nuclear  ... \"\n",
      "SUCESSFULLY PARSED 2022PhRvL.128x1802A: \" {MicroBooNE and the {\\ensuremath{\\nu}}$_{e}$ Interpretation  ... \"\n",
      "SUCESSFULLY PARSED 2021arXiv210903831A: \" {Heavy neutral leptons below the kaon mass at hodoscopic det ... \"\n",
      "SUCESSFULLY PARSED 2020RPPh...83l4201A: \" {New opportunities at the next-generation neutrino experimen ... \"\n",
      "SUCESSFULLY PARSED 2020arXiv201202142H: \" {Novel multi-lepton signatures of dark sectors in light meso ... \"\n",
      "SUCESSFULLY PARSED 2020PhRvD.102e5016H: \" {Pair production of dark particles in meson decays}  \"\n",
      "SUCESSFULLY PARSED 2021PhRvD.104e5031H: \" {Constraints on decaying sterile neutrinos from solar antine ... \"\n",
      "SUCESSFULLY PARSED 2021PhLB..82036531A: \" {A dark seesaw solution to low energy anomalies: MiniBooNE,  ... \"\n",
      "SUCESSFULLY PARSED 2020PhRvD.101k5025B: \" {Dark neutrinos and a three-portal connection to the standar ... \"\n",
      "SUCESSFULLY PARSED 2019PhRvL.123z1801A: \" {Testing New Physics Explanations of the MiniBooNE Anomaly a ... \"\n",
      "SUCESSFULLY PARSED 2019PhRvD.100e5012B: \" {Zprime in neutrino scattering at DUNE}  \"\n",
      "SUCESSFULLY PARSED 2019arXiv190700991B: \" {Neutrino Non-Standard Interactions: A Status Report}  \"\n",
      "SUCESSFULLY PARSED 2019PhRvD..99i1701B: \" {Neutrino masses from a dark neutrino sector below the elect ... \"\n",
      "SUCESSFULLY PARSED 2019JHEP...01..119B: \" {Neutrino trident scattering at near detectors}  \"\n",
      "SUCESSFULLY PARSED 2017arXiv170509214B: \" {Light Sterile Neutrinos at $\\nu$STORM: Decoherence and CP v ... \"\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir('../_publications'):\n",
    "    os.remove(os.path.join('../_publications', f))\n",
    "\n",
    "    \n",
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = stripchar_plain(b[\"title\"])\n",
    "\n",
    "            \n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = stripchar_plain(str(pub_date) + \"-\" + url_slug + \".md\")\n",
    "            html_filename = stripchar_plain(str(pub_date) + \"-\" + url_slug)\n",
    "\n",
    "            \n",
    "            \n",
    "            #########################################\n",
    "            # citation authors\n",
    "            author_citation = \"\"\n",
    "            authors = bibdata.entries[bib_id].persons[\"author\"]\n",
    "            for author in authors:\n",
    "                author_citation += \" \"\\\n",
    "                            +stripchar_rich(author.first_names[0])+\" \"\\\n",
    "                            +stripchar_rich(author.last_names[0])+\", \"\n",
    "                \n",
    "            if len(authors) > 10:\n",
    "                author_citation = stripchar_rich(authors[0].first_names[0])+\" \"\\\n",
    "                            +stripchar_rich(authors[0].last_names[0])+\" and others, \"\n",
    "\n",
    "            ##########################################\n",
    "            # Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            # citation title\n",
    "            citation += \"\\\"\" + stripchar_rich(b[\"title\"]) + \"\\\",\"\n",
    "            \n",
    "            # citation author list\n",
    "            citation += author_citation \n",
    "            \n",
    "            # add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+stripchar_rich(b[publist[pubsource][\"venuekey\"]])\n",
    "            \n",
    "            if venue == 'prd':\n",
    "                venue = '<strong>PRD</strong>'\n",
    "            if venue == 'prl':\n",
    "                venue = '<strong>PRL</strong>'\n",
    "            if venue == 'arXiv e-prints':\n",
    "                venue = '<em>arXiv preprint</em>'\n",
    "\n",
    "            citation += \" \" + html_escape(venue)\n",
    "            citation += \", \" + pub_year\n",
    "\n",
    "            ##########################################\n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + stripchar_rich(b[\"title\"])+ '\"\\n'\n",
    "\n",
    "            md += \"\"\"authors: \"\"\"   + html_escape(author_citation)[:-2] + '\\n'\n",
    "\n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "            \n",
    "            md += \"\\ncitation: '\" + citation + \", '\"\n",
    "\n",
    "            md += \"\\neprint: '\" + html_escape(b[\"eprint\"]) +\"'\\n\"\n",
    "\n",
    "            md += \"---\"\n",
    "                \n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = bibtex.Parser()\n",
    "bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "#loop through the individual references in a given bibtex file\n",
    "for bib_id in bibdata.entries:\n",
    "    #reset default date\n",
    "    pub_year = \"1900\"\n",
    "    pub_month = \"01\"\n",
    "    pub_day = \"01\"\n",
    "\n",
    "    b = bibdata.entries[bib_id].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of citations: 543; Excluding self cites: 299\n",
      "\n",
      "Not saved.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'old_biblio.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matheushostert/Repos/website/markdown_generator/PubsFromBib.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheushostert/Repos/website/markdown_generator/PubsFromBib.ipynb#ch0000009?line=78'>79</a>\u001b[0m     exit()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheushostert/Repos/website/markdown_generator/PubsFromBib.ipynb#ch0000009?line=80'>81</a>\u001b[0m \u001b[39m#Load snapshot\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matheushostert/Repos/website/markdown_generator/PubsFromBib.ipynb#ch0000009?line=81'>82</a>\u001b[0m old_biblio \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(FILENAME)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheushostert/Repos/website/markdown_generator/PubsFromBib.ipynb#ch0000009?line=83'>84</a>\u001b[0m \u001b[39m#Get a set of paper IDs that were added/removed/stayed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheushostert/Repos/website/markdown_generator/PubsFromBib.ipynb#ch0000009?line=84'>85</a>\u001b[0m new_paper_ids \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(    biblio[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'old_biblio.npy'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "Given an author identified by his/her BAI, this Python3 script counts the number of\n",
    "citations and the number of citations excluding self cites in the Inspirehep database\n",
    "(https://inspirehep.net/) for each author's paper.\n",
    "Additionally, it allows saving a snapshot for later detection of new/removed papers and\n",
    "change in the number of citations of individual papers\n",
    "Built on & inspired by https://github.com/efranzin/python\n",
    "\"\"\"\n",
    "\n",
    "AUTHOR             = 'M.Hostert.1'\n",
    "MAX_NUM_PAPERS     = 1000       #Number of papers requested from INSPIRE-HEP\n",
    "SHORT_TITLE_LENGTH = 50         #Shorten long paper titles\n",
    "NEED_WRITE_CONFIRM = True       #Whether to ask user for permission to save to disk\n",
    "FILENAME           = 'old_biblio.npy'\n",
    "\n",
    "# Import the modules to open and reading URLs and the JSON encoder\n",
    "\n",
    "# Open the INSPIRE-HEP profile\n",
    "inspirehep_profile = 'https://inspirehep.net/api/literature?sort=mostrecent&size=' + \\\n",
    "                        str(MAX_NUM_PAPERS) + '&q=a%20' + AUTHOR\n",
    "\n",
    "# Load the data\n",
    "data     = json.loads(urllib.request.urlopen(inspirehep_profile).read())\n",
    "num_hits = data['hits']['total']\n",
    "\n",
    "# Data type to store paper id, beginning of the title, number of citations and number of\n",
    "# citations without self-citations\n",
    "bibliography_dtype = np.dtype([\n",
    "                        ('id',          np.int64),\n",
    "                        ('title',       np.unicode_, SHORT_TITLE_LENGTH),\n",
    "                        ('cits',        np.int64),\n",
    "                        ('cits_noself', np.int64),\n",
    "                    ])\n",
    "\n",
    "# Fill in information about author's papers from the website response\n",
    "biblio = np.zeros(num_hits, dtype = bibliography_dtype)\n",
    "\n",
    "for i in range(num_hits):\n",
    "    biblio[i]['id']          = data['hits']['hits'][i]['id']\n",
    "    biblio[i]['title']       = data['hits']['hits'][i]['metadata']['titles'][0]['title']\n",
    "    biblio[i]['cits']        = data['hits']['hits'][i]['metadata']['citation_count']\n",
    "    biblio[i]['cits_noself'] = data['hits']['hits'][i]['metadata']['citation_count_without_self_citations']\n",
    "\n",
    "# Print the total number of citations and the total number of citations excluding self cites\n",
    "print(\n",
    "        '\\nTotal number of citations: ', \n",
    "        sum(biblio['cits']), \n",
    "        '; Excluding self cites: ', \n",
    "        sum(biblio['cits_noself']), \n",
    "        '\\n',\n",
    "        sep=''\n",
    "    )\n",
    "\n",
    "# Function to save current snapshot of the author's citations\n",
    "def save_snapshot():\n",
    "    \"\"\"\n",
    "    Saves a current snapshot of the bibliography. \n",
    "    If NEED_WRITE_CONFIRM is True, asks the user for permission first.\n",
    "    \"\"\"\n",
    "\n",
    "    if NEED_WRITE_CONFIRM:\n",
    "        rewrite = input('\\nDo you want to save a snapshot [y/n]? ')\n",
    "        if rewrite != 'y':\n",
    "            print('Not saved.')\n",
    "            return\n",
    "\n",
    "    np.save(FILENAME, biblio)\n",
    "    print('Saved.')\n",
    "    return\n",
    "\n",
    "#If snapshot does not exist, create it (potentially confirming with the user) and exit\n",
    "from os.path import exists\n",
    "if not exists(FILENAME):\n",
    "    save_snapshot()\n",
    "    exit()\n",
    "\n",
    "#Load snapshot\n",
    "old_biblio = np.load(FILENAME)\n",
    "\n",
    "#Get a set of paper IDs that were added/removed/stayed\n",
    "new_paper_ids = set(    biblio['id'])\n",
    "old_paper_ids = set(old_biblio['id'])\n",
    "\n",
    "added_paper_ids   = new_paper_ids.difference(old_paper_ids)\n",
    "removed_paper_ids = old_paper_ids.difference(new_paper_ids)\n",
    "stayed_paper_ids  = new_paper_ids.intersection(old_paper_ids)\n",
    "\n",
    "#Keep track of whether we had any changes\n",
    "changes_present = False\n",
    "\n",
    "#Print information about papers that were added or removed\n",
    "for i in removed_paper_ids:\n",
    "    changes_present = True\n",
    "\n",
    "    idx       = np.argmax(old_biblio['id'] == i)\n",
    "    title     = old_biblio[idx]['title'] \n",
    "    num_cites = old_biblio[idx]['cits']\n",
    "\n",
    "    if num_cites == 1:\n",
    "        print('Removed paper: \"' + title + '\" with ' +  str(num_cites) + ' citation')\n",
    "    else:\n",
    "        print('Removed paper: \"' + title + '\" with ' +  str(num_cites) + ' citations')\n",
    "\n",
    "for i in added_paper_ids:\n",
    "    changes_present = True\n",
    "\n",
    "    idx       = np.argmax(biblio['id'] == i)\n",
    "    title     = biblio[idx]['title'] \n",
    "    num_cites = biblio[idx]['cits']\n",
    "\n",
    "    if num_cites == 1:\n",
    "        print('Added paper: \"' + title + '\" with ' +  str(num_cites) + ' citation')\n",
    "    else:\n",
    "        print('Added paper: \"' + title + '\" with ' +  str(num_cites) + ' citations')\n",
    "\n",
    "#For papers not added or removed, check if number of citations has changed\n",
    "for i in stayed_paper_ids:\n",
    "\n",
    "    idx_old       = np.argmax(old_biblio['id'] == i)\n",
    "    idx_new       = np.argmax(    biblio['id'] == i)\n",
    "    title         = biblio[idx_new]['title'] \n",
    "    num_new_cites = biblio[idx_new]['cits'] - old_biblio[idx_old]['cits']\n",
    "\n",
    "    if num_new_cites != 0:\n",
    "        changes_present = True\n",
    "\n",
    "        if   num_new_cites == 1:\n",
    "            print('1 new citation: \"' + title + '\"')\n",
    "        elif num_new_cites == -1:\n",
    "            print('1 citation removed: \"' + title + '\"')\n",
    "        elif num_new_cites  > 1:\n",
    "            print(str(num_new_cites) + ' new citations: \"' + title + '\"')\n",
    "        elif num_new_cites  < -1:\n",
    "            print(str(abs(num_new_cites)) + ' citations removed: \"' + title + '\"')\n",
    "\n",
    "#Save current snapshot if anything changed (potentially confirming with the user)\n",
    "if changes_present:\n",
    "    save_snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "response = requests.get(f\"https://inspirehep.net/api/literature?q=author:{ref}&format=bibtex\")\n",
    "    if response.status_code == 200:\n",
    "        f.write((response.content).decode(\"utf-8\") )\n",
    "        added_ids.append(ref)\n",
    "    else:\n",
    "        print(f\"Could not find Inspire entry for texkey={ref}.\")\n",
    "\n",
    "\n",
    "MY_AUTHOR_ID = '1621061'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbc1128b55dfe7674910d9dec9178b9135ab71c646c7080f47e59389499c8905"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
